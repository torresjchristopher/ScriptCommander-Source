# Nemo Synthesis Engine - Phase 3.2+ (Four-Button + TTS)

**Pure Intelligence. No Storage. No Recording. Just Synthesis. Voice In. Voice Out.**

## The Four-Button Interface (NEW!)

### Button 1: RIGHT ALT = Internet AI (Voice Input)
Press to activate Gemini AI via voice. The AI butler responds with voice.

### Button 2: LEFT ALT (tap) = TTS Button (Voice Output) â­ NEW!
Tap to HEAR Nemo's synthesis. Your context. Your patterns. Spoken aloud.
**This is the human element. Voice replaces qwerty.**

### Button 3: LEFT ALT + LEFT ARROW = REWIND
Hold to infer what WAS on screen. Pure synthesis, not replay.

### Button 4: LEFT ALT + RIGHT ARROW = FORWARD  
Hold to predict what COMES NEXT. Based on your behavior patterns.

## The Vision: Replacing QWERTY

**Old way:** Type words into computer, read response.
**New way (Nemo):** Speak to computer, hear understanding.

TTS is the human element. Voice input (RIGHT ALT) + voice output (LEFT ALT) = natural interaction.

## Zero Audio Storage: Top-Line Security

### What NEVER Persists
```
âŒ No voice recordings
âŒ No audio files  
âŒ No microphone cache
âŒ No temp audio files
âŒ No audio in logs
âŒ No clipboard audio
âŒ No audio in memory (cleared after playback)
```

### How Voice Works
```
User speaks (RIGHT ALT) â†’ 
Audio captured (in-memory) â†’ 
Sent to Google Speech-to-Text â†’
Audio buffer deleted immediately â†’
Text sent to Gemini â†’
Response text converted to speech (in-memory) â†’
Audio played through speakers/headphones â†’
Speech buffer deleted immediately â†’

RESULT: Zero audio storage. Pure text synthesis.
```

### Security Audit (NEW!)
```bash
nemo security verify          # Verify zero-storage guarantee
nemo security report          # Full audit report
nemo security report --verbose # Detailed findings
```

## Three-Button Interface (Original)
Hold to simulate what was on screen N seconds ago.
Uses keyboard signature + screen context to infer the past.

```
What the system knows:
  â€¢ You were typing in email app (screen analyzer)
  â€¢ Your pattern shows "composition" (keyboard synthesizer)
  â€¢ You're being deliberate, not rapid-firing

System infers:
  "5 seconds ago, you were still drafting the email body"
  Confidence: 85%
```

### 2. LEFT ALT + RIGHT ARROW = FORWARD
Hold to predict what comes next.
Uses intent + context to predict the future.

```
What the system knows:
  â€¢ Email form is complete (screen analyzer)
  â€¢ Keyboard pattern shows "ready to send" (synthesizer)
  â€¢ Next natural step in workflow

System predicts:
  "Your next action is likely clicking Send"
  Confidence: 80%
```

### 3. RIGHT ALT = VOICE (AI Butler)
Hold to talk to your Gemini AI assistant.
Responds with voice like a personal butler.

```
User presses RIGHT ALT and says:
  "What was I typing 3 minutes ago?"

System:
  1. Records voice input
  2. Converts to text
  3. Adds context: keyboard + screen state
  4. Sends to Gemini with synthesis context
  5. Gemini responds with AI answer
  6. Converts to speech
  7. Plays response
```

## Zero Storage Architecture

### What We DO NOT Do
âŒ Store screenshots
âŒ Record video
âŒ Save action history
âŒ Persist data
âŒ Track user activity

### What We DO Do
âœ… Analyze current screen state
âœ… Learn keyboard patterns (real-time)
âœ… Synthesize intent from keyboard + screen
âœ… Infer past and future from synthesis
âœ… Forget everything (ephemeral analysis)

## Four Core Components

### 1. Screen Analyzer (6.8K LOC)
Analyzes what's currently visible on screen.
No storage - just analysis of current state.

```python
from screen_analyzer import get_screen_analyzer

analyzer = get_screen_analyzer()
state = analyzer.analyze_current_screen()
```

Detects:
- Active window and application
- Visible UI elements
- Form fields and labels
- Content type (email, code, web, document)
- Language detection

### 2. Keyboard Synthesizer (9.4K LOC)
Learns your unique keystroke patterns in real-time.
Builds and updates your 35-D behavioral fingerprint.

```python
from keyboard_synthesizer import get_keyboard_synthesizer

synth = get_keyboard_synthesizer()
synth.record_keystroke(key="a", duration_ms=150)

# Continuously updated 35-D signature:
# - 12-D: timing (dwell, flight, intervals)
# - 8-D: pressure characteristics
# - 10-D: patterns (entropy, rhythm, bursts)
# - 5-D: intent (search, editing, coding, navigation, composition)
```

### 3. Temporal Inference Engine (11.2K LOC)
Infers what WAS (rewind) and what WILL BE (forward).
Uses keyboard signature + screen context.

```python
from temporal_inference import get_temporal_inference_engine

engine = get_temporal_inference_engine()

# What was 5 seconds ago?
past = engine.infer_rewind(seconds_back=5)

# What happens next?
future = engine.infer_forward(seconds_ahead=5)

# Returns: confidence score, likely actions, reasoning
```

### 4. Gemini Integration (10.1K LOC)
Live AI assistant with Google OAuth and credit management.
Supports Gemini, Claude, and Ollama (open source).

```python
from gemini_integration import get_gemini_integration

gemini = get_gemini_integration()

# Google OAuth login
gemini.set_credentials(oauth_code)

# Query with screen+keyboard context
response = gemini.query(
    text="What was I typing?",
    context={"active_app": "outlook", "intent": "composition"}
)

# Manage credits
balance = gemini.get_balance()
gemini.add_credit(amount_usd=10)
```

## CLI Commands

### Setup & First-Run
```bash
nemo setup                      # Interactive setup wizard
nemo buttons                    # Show button mapping
nemo help                       # Show all commands
```

### Account & Payments
```bash
nemo account link              # Google OAuth login
nemo account status            # Show linked accounts
nemo credits show              # View API credit balance
nemo credits refill            # Add credits ($5, $10, $25, custom)
nemo credits history           # Show usage history
```

### Agent Management
```bash
nemo agent list                # Show available agents
nemo agent status              # Check connection
nemo agent switch gemini       # Switch to Gemini
nemo agent switch claude       # Switch to Claude
nemo agent switch ollama       # Switch to Ollama (local)
```

### Analysis & Synthesis
```bash
nemo synthesis analyze         # Analyze current state
nemo rewind --seconds 5        # Infer what was 5 sec ago
nemo forward --seconds 5       # Predict next 5 seconds
```

### Voice Assistant
```bash
nemo voice start               # Start voice daemon
nemo voice status              # Show voice connection
nemo voice test                # Test voice hotkey
nemo voice configure           # Configure voice settings
```

## First-Run Experience

### Step 1: User Presses RIGHT ALT (First Time)
```
"Welcome to Nemo!"
"Open terminal and run: nemo setup"
```

### Step 2: User Runs `nemo setup`
Interactive wizard:
1. Welcome message
2. Select AI agent (Gemini recommended)
3. Link Google account (OAuth)
4. Add API credits
5. Test voice hotkey
6. Done!

### Step 3: All Set
```
Quick Start:
  â€¢ RIGHT ALT = Talk to AI
  â€¢ LEFT ALT + LEFT ARROW = Rewind
  â€¢ LEFT ALT + RIGHT ARROW = Forward
```

## Payment & Credits System

### Pricing
Pay-per-use model. You control costs.

```
Gemini Pricing Examples:
  â€¢ 1,000 queries â‰ˆ $1
  â€¢ 10,000 queries â‰ˆ $10
  â€¢ 100,000 queries â‰ˆ $100
```

### Credit Management
```bash
nemo credits show
# Output:
# Balance: $2.50 (1.25M tokens)
# Usage This Month: $1.20
# Last Refill: Jan 30, 2026

nemo credits refill
# Choose: $5, $10, $25, or custom
# Payment via Stripe (built into CLI)
# Credits added immediately
```

## Multi-Agent Support

### Gemini (Default - Recommended)
- Latest AI models
- Multimodal (text, image, audio)
- Fast responses
- Pay-per-use ($0.0005 per 1K tokens)
- Requires Google account

### Claude (Anthropic)
- Long context window
- Thoughtful reasoning
- Pay-per-use
- Switch with: `nemo agent switch claude`

### Ollama (Open Source)
- Runs locally on your computer
- Completely free
- No internet required
- 100% private
- Slower but no costs
- Setup: Download Ollama, run `ollama pull llama2`

## Privacy First

âœ… **No Cloud Storage**
- All analysis stays local
- Nothing sent to Nemo servers
- Nothing persists

âœ… **Direct to Providers**
- Gemini API: Direct to Google
- Claude API: Direct to Anthropic
- Ollama: Runs on your machine

âœ… **Encrypted Credentials**
- OAuth tokens stored locally
- API keys encrypted
- Never transmitted to Nemo

âœ… **Voice is Optional**
- Voice data sent only to chosen provider
- User controls what's shared
- Can use text-only mode

âœ… **Open Source Alternative**
- Ollama runs everything locally
- No internet needed
- Completely private

## Use Cases

### Email Composition
```
User: "Was my email professional?"
Nemo: Analyzes email + your typing pattern
Response: "Yes, it sounds professional and clear"
```

### Coding Session
```
User holds LEFT ALT + LEFT ARROW (rewind)
System: Infers you were debugging 5 minutes ago
Shows: "You were tracing through the authentication logic"
```

### Shopping Recovery
```
User: "Did I add the blue or red variant?"
Nemo: Checks screen + your selection pattern
Response: "You selected the blue variant, which is in your cart"
```

### Meeting Notes
```
User: "What did I write about budgets?"
Nemo: Synthesizes meeting notes + your typing rhythm
Response: "You noted Q4 budget approval needed by March 15"
```

## Architecture

```
USER PRESSES BUTTON
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LEFT+LEFT  â”‚  LEFT+RIGHT  â”‚  RIGHT   â”‚
â”‚  (REWIND)   â”‚  (FORWARD)   â”‚  (VOICE) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCREEN ANALYZER: What's visible?            â”‚
â”‚ KEYBOARD SYNTHESIZER: Your pattern?         â”‚
â”‚ TEMPORAL INFERENCE: Past/Future?            â”‚
â”‚ GEMINI: What should I tell user?            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ANALYSIS (no storage)
    â†“
DISPLAY RESULT
```

## Technology

- **Python 3.9+** - Core language
- **click** - CLI framework
- **rich** - Terminal UI
- **numpy** - Numerical computing
- **google-generativeai** - Gemini API client
- **anthropic** - Claude API client
- **google-auth** - OAuth
- **pyaudio** - Voice I/O
- **SpeechRecognition** - Speech-to-text
- **google-cloud-texttospeech** - Text-to-speech

## Installation

```bash
# Clone repository
git clone <repo-url>
cd nemo

# Install dependencies
pip install -r requirements.txt

# Run setup
python cli.py setup
```

## Testing

```bash
# Test components
python -m pytest tests/

# Manual testing
python cli.py synthesis analyze
python cli.py voice test
python cli.py agent status
```

## Philosophy

**"Perfect Intelligence Without Perfect Storage"**

Traditional systems:
- Record everything
- Store everything
- Replay everything

Nemo:
- Understand everything
- Forget everything
- Remember nothing

We achieve perfect intelligence through **synthesis**, not storage.

---

**Based on: The Blanket Theory**

Just as God synthesizes all perspectives into omniscience,
Nemo synthesizes keyboard + screen into user omniscience.

Not storage. Not replay. **Synthesis.**

The future of AI isn't recording the past.
It's understanding the present.

ğŸ§ 
